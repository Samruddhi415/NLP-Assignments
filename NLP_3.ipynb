{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPf6eZMts4ESDp3f610OSga"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TZyh3tn1QOm1","executionInfo":{"status":"ok","timestamp":1739264979793,"user_tz":-330,"elapsed":4622,"user":{"displayName":"Samruddhi Kathale","userId":"11453889790279965058"}},"outputId":"b235e3a6-80a9-4b91-f001-a9ba7428b13e"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Cleaned Text: ['example sentence', 'text preprocessing important nlp', 'removing stopwords lemmatization help']\n","Encoded Labels: [0 1 2]\n","TF-IDF Representation: [[0.70710678 0.         0.         0.         0.         0.\n","  0.         0.70710678 0.         0.        ]\n"," [0.         0.         0.5        0.         0.5        0.5\n","  0.         0.         0.         0.5       ]\n"," [0.         0.5        0.         0.5        0.         0.\n","  0.5        0.         0.5        0.        ]]\n","TF-IDF output saved as tfidf_output.csv\n"]}],"source":["import nltk\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","import pandas as pd\n","from nltk.corpus import stopwords\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from nltk.tokenize import TreebankWordTokenizer\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","# Sample dataset\n","data = [\"This is an example sentence!\",\n","        \"Text preprocessing is important for NLP.\",\n","        \"Removing stopwords and lemmatization help.\"]\n","\n","labels = [\"A\", \"B\", \"C\"]\n","\n","# Text Cleaning\n","stop_words = set(stopwords.words('english'))\n","lemmatizer = nltk.WordNetLemmatizer()\n","\n","tokenizer = TreebankWordTokenizer()\n","cleaned_text = []\n","for sentence in data:\n","    words = tokenizer.tokenize(sentence.lower())  # Use alternative tokenizer\n","    words = [lemmatizer.lemmatize(word) for word in words if word.isalnum() and word not in stop_words]  # Remove stopwords\n","    cleaned_text.append(\" \".join(words))\n","\n","print(\"Cleaned Text:\", cleaned_text)\n","\n","# Label Encoding\n","label_encoder = LabelEncoder()\n","encoded_labels = label_encoder.fit_transform(labels)\n","print(\"Encoded Labels:\", encoded_labels)\n","\n","# TF-IDF Representation\n","tfidf_vectorizer = TfidfVectorizer()\n","tfidf_matrix = tfidf_vectorizer.fit_transform(cleaned_text)\n","print(\"TF-IDF Representation:\", tfidf_matrix.toarray())\n","\n","# Saving outputs\n","df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n","df[\"Label\"] = encoded_labels\n","df.to_csv(\"tfidf_output.csv\", index=False)\n","print(\"TF-IDF output saved as tfidf_output.csv\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"VKUeprStQZsA"},"execution_count":null,"outputs":[]}]}